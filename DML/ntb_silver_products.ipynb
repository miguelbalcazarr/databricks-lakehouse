{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df1a3e93-edf6-4614-bbe3-b22de60a6188",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72cbc76b-3a73-4a7e-8d3e-ca5c3666c1f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "container = dbutils.secrets.get(\"scope-mbc\", \"secret-env-container\")\n",
    "storage_account = dbutils.secrets.get(\"scope-mbc\", \"secret-env-storage-account\")\n",
    "path_base = f\"abfss://{container}@{storage_account}.dfs.core.windows.net\"\n",
    "\n",
    "# Configuración de nombres de tablas\n",
    "tables = {\n",
    "    \"products\": {\n",
    "        \"bronze\": \"bronze.products\",\n",
    "        \"silver\": \"silver.products\",\n",
    "        \"checkpoint\": f\"{path_base}/checkpoints/bronze_to_silver/products/\"\n",
    "    },\n",
    "    \"orders\": {\n",
    "        \"bronze\": \"bronze.orders\",\n",
    "        \"silver\": \"silver.orders\",\n",
    "        \"checkpoint\": f\"{path_base}/checkpoints/bronze_to_silver/orders/\"\n",
    "    },\n",
    "    \"order_items\": {\n",
    "        \"bronze\": \"bronze.order_items\",\n",
    "        \"silver\": \"silver.order_items\",\n",
    "        \"checkpoint\": f\"{path_base}/checkpoints/bronze_to_silver/order_items/\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1593ce28-3c6b-4612-86bb-eec94a85e0dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform_products(df):\n",
    "    \"\"\"Transformaciones para la tabla products\"\"\"\n",
    "    current_year = year(current_date())\n",
    "    \n",
    "    return df.withColumns({\n",
    "        \"product_name\": trim(col(\"product_name\")),\n",
    "        \"model_year_clean\": when(col(\"model_year\") < 2000, 2000)\n",
    "                          .when(col(\"model_year\") > current_year + 1, current_year)\n",
    "                          .otherwise(col(\"model_year\")),\n",
    "        \"list_price_clean\": round(col(\"list_price\"), 2),\n",
    "        \"is_active\": lit(True),  # Nuevo campo\n",
    "        \"processed_at\": current_timestamp(),\n",
    "        \"source_system\": lit(\"legacy_system\")  # Metadata\n",
    "    })\n",
    "\n",
    "def write_to_silver(table_name, transform_function):\n",
    "    \"\"\"Función genérica para escribir datos en silver\"\"\"\n",
    "    config = tables[table_name]\n",
    "    \n",
    "    def foreach_batch_function(df, batch_id):\n",
    "        # Aplicar transformaciones\n",
    "        transformed_df = transform_function(df)\n",
    "        \n",
    "        # Validar esquema\n",
    "        expected_columns = spark.table(config[\"silver\"]).columns if spark.catalog.tableExists(config[\"silver\"]) else transformed_df.columns\n",
    "        missing_columns = [col for col in expected_columns if col not in transformed_df.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"Faltan columnas en el DataFrame transformado: {missing_columns}\")\n",
    "        \n",
    "        # Escribir en Silver\n",
    "        (transformed_df\n",
    "         .write\n",
    "         .format(\"delta\")\n",
    "         .mode(\"append\")\n",
    "         .option(\"mergeSchema\", \"true\")  # Permite evolución del esquema\n",
    "         .saveAsTable(config[\"silver\"]))\n",
    "    \n",
    "    # Iniciar el stream\n",
    "    (spark.readStream\n",
    "     .format(\"delta\")\n",
    "     .table(config[\"bronze\"])\n",
    "     .writeStream\n",
    "     .foreachBatch(foreach_batch_function)\n",
    "     .option(\"checkpointLocation\", config[\"checkpoint\"])\n",
    "     .option(\"maxFilesPerTrigger\", 100)  # Controlar el tamaño del lote\n",
    "     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c6dd6d6-37ca-4d7a-aae1-4081da83e6a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Diccionario para controlar los streams activos\n",
    "active_streams = {}\n",
    "\n",
    "# Iniciar stream para products\n",
    "active_streams[\"products\"] = write_to_silver(\"products\", transform_products)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ntb_silver_products",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
